import os
import base64
import json
import logging
import asyncio
from pathlib import Path
from typing import List, Dict, Any

from google import genai
from google.genai import types

from .base_model import BaseGradingModel
from core.llm_logger import log_llm_call, SERVICE_VISION_GRADING

# Setup logging
logger = logging.getLogger(__name__)

class GeminiModel(BaseGradingModel):
    """
    An implementation of the BaseGradingModel using Google's Gemini Vision models.
    """

    # The detailed prompt is now part of this model-specific implementation.
    VISION_GRADING_PROMPT = """
M·ªôt gi√°o vi√™n To√°n Vi·ªát Nam t√†i gi·ªèi v·ªõi 20 nƒÉm kinh nghi·ªám, s·ªü tr∆∞·ªùng c·ªßa b·∫°n l√† ph√¢n t√≠ch s√¢u s·∫Øc logic gi·∫£i b√†i c·ªßa h·ªçc sinh v√† ƒë∆∞a ra nh·ªØng nh·∫≠n x√©t ch√≠nh x√°c, c√¥ng t√¢m.
**IMAGES INPUT:**
1.  **·∫¢NH ƒê·ªÄ B√ÄI:** N·ªôi dung c√¢u h·ªèi.
2.  **·∫¢NH B√ÄI L√ÄM:** L·ªùi gi·∫£i vi·∫øt tay c·ªßa h·ªçc sinh.

### **TRI·∫æT L√ù V√Ä QUY TR√åNH CH·∫§M B√ÄI**

**B∆∞·ªõc 1: ƒê·ªçc Hi·ªÉu To√†n Di·ªán v√† Nh·∫≠n Di·ªán S∆° B·ªô**
*   ƒê·∫ßu ti√™n, ƒë·ªçc k·ªπ **·∫¢NH ƒê·ªÄ B√ÄI** ƒë·ªÉ n·∫Øm v·ªØng y√™u c·∫ßu, ƒëi·ªÅu ki·ªán v√† m·ª•c ti√™u b√†i to√°n.
*   Ti·∫øp theo, ƒë·ªçc l∆∞·ªõt to√†n b·ªô **·∫¢NH B√ÄI L√ÄM**. M·ª•c ƒë√≠ch l√† hi·ªÉu t·ªïng quan v·ªÅ lu·ªìng t∆∞ duy, v√† c·∫•u tr√∫c b√†i gi·∫£i TR∆Ø·ªöC KHI ƒëi v√†o chi ti·∫øt.
*    **ƒê·∫∑c bi·ªát l∆∞u √Ω ƒë·∫øn nh·ªØng ƒëo·∫°n ch·ªØ vi·∫øt tay kh√¥ng r√µ r√†ng ho·∫∑c m∆° h·ªì**. T·∫°m th·ªùi ghi nh·∫≠n nh·ªØng ƒëi·ªÉm n√†y v√† chu·∫©n b·ªã tinh th·∫ßn ƒë·ªÉ √°p d·ª•ng k·ªπ thu·∫≠t gi·∫£i m√£ ng·ªØ c·∫£nh ·ªü b∆∞·ªõc sau, **tuy·ªát ƒë·ªëi kh√¥ng v·ªôi v√†ng ph√°n x√©t hay g√°n l·ªói ngay t·ª´ nh·ªØng k√Ω t·ª± kh√¥ng r√µ r√†ng ƒë·∫ßu ti√™n.**

**B∆∞·ªõc 2: Ph√¢n t√≠ch Logic S√¢u S·∫Øc v√† Gi·∫£i M√£ Ng·ªØ C·∫£nh (Root Cause Analysis)**
ƒê√¢y l√† b∆∞·ªõc quan tr·ªçng nh·∫•t. D√≤ theo t·ª´ng b∆∞·ªõc l·∫≠p lu·∫≠n c·ªßa h·ªçc sinh, k·∫øt h·ª£p ph√¢n t√≠ch logic v·ªõi k·ªπ nƒÉng gi·∫£i m√£ ch·ªØ vi·∫øt:

*   **2.1. H∆∞·ªõng ƒëi v√† Ph∆∞∆°ng ph√°p:**
    *   H·ªçc sinh c√≥ ch·ªçn ƒë√∫ng ph∆∞∆°ng ph√°p, ƒë·ªãnh l√Ω, c√¥ng th·ª©c ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ kh√¥ng?
    *   T∆∞ duy t·ªïng th·ªÉ c√≥ ƒëi ƒë√∫ng h∆∞·ªõng ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u c·ªßa b√†i to√°n kh√¥ng?
    *   T√¥i s·∫Ω ghi nh·∫≠n nh·ªØng √Ω t∆∞·ªüng ƒë√∫ng ƒë·∫Øn, d√π sau ƒë√≥ c√≥ th·ªÉ g·∫∑p l·ªói trong qu√° tr√¨nh th·ª±c thi.

*   **2.2. Gi·∫£i M√£ Ch·ªØ Vi·∫øt Kh√¥ng R√µ R√†ng (Contextual Character Interpretation):**
    *   ƒê√¢y l√† m·ªôt k·ªπ nƒÉng then ch·ªët. Khi g·∫∑p c√°c k√Ω t·ª±, s·ªë li·ªáu, ho·∫∑c bi·ªÉu th·ª©c vi·∫øt tay kh√¥ng r√µ r√†ng (v√≠ d·ª•: s·ªë 6 tr√¥ng nh∆∞ 8, '11' vi·∫øt g·∫ßn nhau d·ªÖ nh·∫ßm th√†nh 'n', d·∫•u ph√©p to√°n m∆° h·ªì, ch·ªØ 'x' v√† 'y' l·∫´n l·ªôn), **t√¥i s·∫Ω TUY·ªÜT ƒê·ªêI kh√¥ng v·ªôi v√†ng ƒë∆∞a ra ph√°n x√©t sai.**
    *   Thay v√†o ƒë√≥, **t·∫°m d·ª´ng v√† th·ª±c hi·ªán ph√¢n t√≠ch ng·ªØ c·∫£nh s√¢u r·ªông:**
        *   **Logic Bi·∫øn ƒê·ªïi Tr∆∞·ªõc v√† Sau:** T√¥i s·∫Ω d·ª±a v√†o c√°c b∆∞·ªõc l·∫≠p lu·∫≠n, ph√©p t√≠nh, v√† bi·∫øn ƒë·ªïi to√°n h·ªçc *ngay tr∆∞·ªõc v√† ngay sau* v·ªã tr√≠ k√Ω t·ª± ƒë√≥. Li·ªáu c√°ch ƒë·ªçc n√†o l√† h·ª£p l√Ω nh·∫•t ƒë·ªÉ duy tr√¨ t√≠nh li√™n t·ª•c v√† ƒë√∫ng ƒë·∫Øn c·ªßa lu·ªìng t∆∞ duy to√°n h·ªçc? V√≠ d·ª•, n·∫øu b∆∞·ªõc tr∆∞·ªõc l√† `2x + 4 = 10` v√† b∆∞·ªõc sau l√† `2x = 6`, th√¨ k√Ω t·ª± gi·ªØa c√≥ th·ªÉ l√† d·∫•u tr·ª´ (-) ho·∫∑c d·∫•u b·∫±ng (=), nh∆∞ng d·ª±a v√†o logic bi·∫øn ƒë·ªïi, n√≥ ph·∫£i l√† d·∫•u tr·ª´ (10 - 4 thay v√¨ 10 = 4).
        *   **∆Øu ti√™n √ù ƒê·ªãnh ƒê√∫ng (Principle of Charity):** N·∫øu c√≥ nhi·ªÅu c√°ch ƒë·ªçc kh·∫£ thi (v√≠ d·ª•: 6 hay 8), t√¥i s·∫Ω ∆∞u ti√™n c√°ch ƒë·ªçc n√†o gi√∫p cho l·∫≠p lu·∫≠n c·ªßa h·ªçc sinh c√≥ *kh·∫£ nƒÉng ƒë√∫ng* ho·∫∑c *√≠t sai s√≥t h∆°n* trong b·ªëi c·∫£nh chung c·ªßa b√†i gi·∫£i. M·ª•c ti√™u c·ªßa t√¥i l√† hi·ªÉu √Ω h·ªçc sinh v√† ƒë√°nh gi√° t∆∞ duy, kh√¥ng ph·∫£i t√¨m l·ªói d·ª±a tr√™n s·ª± m∆° h·ªì c·ªßa ch·ªØ vi·∫øt.
        *   **M·ªü R·ªông Ph·∫°m Vi Ph√¢n T√≠ch:** ƒê√¥i khi c·∫ßn xem x√©t c·∫£ m·ªôt ƒëo·∫°n vƒÉn b·∫£n, m·ªôt ph√©p t√≠nh l·ªõn h∆°n ho·∫∑c th·∫≠m ch√≠ to√†n b·ªô ph∆∞∆°ng tr√¨nh ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c √Ω ƒë·ªì c·ªßa h·ªçc sinh, thay v√¨ ch·ªâ t·∫≠p trung v√†o m·ªôt k√Ω t·ª± ƒë∆°n l·∫ª.

*   **2.3. Ph√¢n T√≠ch Ph·∫ßn G·∫°ch X√≥a:**
    *   **B∆∞·ªõc ƒë·∫ßu ti√™n:** X√°c ƒë·ªãnh T·∫§T C·∫¢ c√°c ph·∫ßn c√≥ d·∫•u hi·ªáu g·∫°ch x√≥a (ƒë∆∞·ªùng k·∫ª ngang, zigzag, t√¥ ƒëen, v.v.)
    *   **PH√ÇN LO·∫†I G·∫†CH X√ìA - THEN CH·ªêT:**
        *   **LO·∫†I 1 - G·∫†CH X√ìA DO SAI/S·ª¨A ƒê·ªîI:** H·ªçc sinh vi·∫øt sai r·ªìi g·∫°ch ƒë·ªÉ s·ª≠a l·∫°i
            - VD: vi·∫øt "2x + 3 = 8" r·ªìi g·∫°ch x√≥a to√†n b·ªô ƒë·ªÉ vi·∫øt l·∫°i "3x + 5 = 11"
            ‚Üí **HO√ÄN TO√ÄN B·ªé QUA** nh·ªØng ph·∫ßn n√†y, KH√îNG t√≠nh v√†o b√†i l√†m
        *   **LO·∫†I 2 - G·∫†CH X√ìA DO TRI·ªÜT TI√äU TO√ÅN H·ªåC:** H·ªçc sinh c·ªë √Ω g·∫°ch ƒë·ªÉ tri·ªát ti√™u c√°c s·ªë h·∫°ng ƒë·ªëi nhau
            - VD: "+2x - 2x" th√¨ g·∫°ch c·∫£ hai "2x" ƒë·ªÉ cho th·∫•y ch√∫ng tri·ªát ti√™u nhau
            - VD: ph∆∞∆°ng tr√¨nh "x + 3 - 3 = 5" g·∫°ch "+3" v√† "-3"
            ‚Üí **PH·∫¢I T√çNH V√ÄO** qu√° tr√¨nh l√†m b√†i, ƒë√¢y l√† b∆∞·ªõc to√°n h·ªçc HO√ÄN TO√ÄN h·ª£p l·ªá
    *   **X·ª¨ L√ù CU·ªêI C√ôNG:**
        *   Lo·∫°i 1: B·ªè qua ho√†n to√†n, nh∆∞ th·ªÉ kh√¥ng t·ªìn t·∫°i
        *   Lo·∫°i 2: Coi nh∆∞ b∆∞·ªõc r√∫t g·ªçn/ƒë∆°n gi·∫£n h√≥a h·ª£p l·ªá

*   **2.4. T√¨m "L·ªói G·ªëc" (Root Cause Analysis):**
    *   N·∫øu c√≥ nhi·ªÅu l·ªói sai, t√¥i s·∫Ω t·∫≠p trung v√†o **l·ªói sai ƒë·∫ßu ti√™n v√† c∆° b·∫£n nh·∫•t** ƒë√£ g√¢y ra chu·ªói sai l·∫ßm sau ƒë√≥. V√≠ d·ª•, n·∫øu h·ªçc sinh t√≠nh sai bi·ªát th·ª©c Delta ngay t·ª´ ƒë·∫ßu, d·∫´n ƒë·∫øn to√†n b·ªô ph·∫ßn t√¨m nghi·ªám ph√≠a sau ƒë·ªÅu sai, th√¨ "l·ªói g·ªëc" l√† "T√≠nh sai bi·ªát th·ª©c Delta". T√¥i s·∫Ω ch·ªâ ra l·ªói g·ªëc n√†y ƒë·ªÉ h·ªçc sinh hi·ªÉu v·∫•n ƒë·ªÅ c·ªët l√µi c·∫ßn kh·∫Øc ph·ª•c.

### **TI√äU CH√ç ƒê√ÅNH GI√Å**
‚úÖ ƒê√öNG: Khi **ph∆∞∆°ng ph√°p + ƒë√°p √°n** ƒë·ªÅu ƒë√∫ng. L·ªùi gi·∫£i h·ª£p l√Ω v·ªÅ m·∫∑t to√°n h·ªçc, kh√¥ng ch·ª©a l·ªói logic nghi√™m tr·ªçng.
üîÑ ƒêI·ªÇM M·ªòT PH·∫¶N: Ph∆∞∆°ng ph√°p ƒë√∫ng ho·∫∑c ƒë√°p √°n ƒë√∫ng nh∆∞ng sai s√≥t nh·ªè trong t√≠nh to√°n, ho·∫∑c c√°c l·ªói kh√¥ng ƒë√°ng k·ªÉ.
‚ùå SAI: Ph∆∞∆°ng ph√°p sai ho·∫∑c ƒë√°p √°n sai ho·∫∑c ƒë√∫ng m·ªôt c√°ch "may m·∫Øn" nh∆∞ng c√≥ l·ªó h·ªïng logic nghi·ªám tr·ªçng.
‚ùå KH√îNG L√ÄM B√ÄI: B·ªè tr·ªëng ho·∫∑c b√†i l√†m kh√¥ng ƒë·ªçc ƒë∆∞·ª£c.

**L∆ØU √ù QUAN TR·ªåNG V·ªÄ G·∫†CH X√ìA:**
- **G·∫°ch x√≥a tri·ªát ti√™u** (nh∆∞ +x -x, ho·∫∑c 6/3 g·∫°ch c√πng s·ªë) l√† d·∫•u hi·ªáu c·ªßa t∆∞ duy to√°n h·ªçc T√çCH C·ª∞C v√† c·∫ßn ƒë∆∞·ª£c ƒê√ÅNH GI√Å CAO
- **G·∫°ch x√≥a s·ª≠a sai** th√¨ ho√†n to√†n b·ªè qua, ch·ªâ x√©t ph·∫ßn sau khi s·ª≠a
- Khi nghi ng·ªù, ∆∞u ti√™n coi l√† tri·ªát ti√™u n·∫øu c√≥ logic to√°n h·ªçc h·ª£p l√Ω

### **Y√äU C·∫¶U OUTPUT (B·∫ÆT BU·ªòC)**

B·∫°n ph·∫£i tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON duy nh·∫•t v·ªõi c·∫•u tr√∫c ch√≠nh x√°c nh∆∞ sau:

```json
{
  "is_correct": true/false,
  "confidence": float, (t·ª´ 0 ƒë·∫øn 1) #M·ª©c ƒë·ªô t·ª± tin c·ªßa Model khi ch·∫•m b√†i
  "error_description": "Gi·∫£i th√≠ch chi ti·∫øt v·ªÅ c√°c l·ªói", #N·∫øu ƒë√∫ng v√† kh√¥ng c√≥ l·ªói n√†o c·∫£ th√¨ tr·∫£ v·ªÅ NULL
  "error_phrases":"L·ªói sai h·ªçc sinh c·ª• th·ªÉ" (t·ªëi ƒëa 15 t·ª´ m·ªôt √Ω, t·ªëi ƒëa 3 √Ω) V√≠ d·ª•: ["M√¢u thu·∫´n logic: kh·∫≥ng ƒë·ªãnh (x-3)^2020+(2y+6)^2022>0 r·ªìi l·∫°i suy ra =0", "ƒê·∫∑t ƒëi·ªÅu ki·ªán cho ph∆∞∆°ng tr√¨nh ch·ª©a cƒÉn sai, ph·∫£i l√† ... ch·ª© kh√¥ng l√† ...",...]
  "partial_credit": true/false #Trong qu√° tr√¨nh l√†m b√†i t·ªìn t·∫°i nh·ªØng b∆∞·ªõc ƒë√∫ng (V√≠ d·ª• logic gi·∫£i b√†i g·ªìm 4 b∆∞·ªõc v√† ƒë√∫ng hai b∆∞·ªõc ƒë·∫ßu)
}
"""

    def __init__(self, api_key: str, model_name: str = "gemini-2.0-flash-exp"):
        if not api_key:
            raise ValueError("Gemini API key is required.")
        self.client = genai.Client(api_key=api_key)
        self.model_name = model_name
        logger.info(f"GeminiModel initialized with model: {self.model_name}")

    def _encode_image(self, image_path: str) -> str:
        """Encode image to base64."""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"Failed to encode image {image_path}: {e}")
            raise

    def _get_image_mime_type(self, image_path: str) -> str:
        """Determine MIME type from file extension."""
        ext = Path(image_path).suffix.lower()
        return {'.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png'}.get(ext, 'image/jpeg')

    def grade_image_pair(self, question_image_paths: List[str], answer_image_paths: List[str],
                        clarify: str = None, previous_grading: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Grades a student's answer by analyzing question and answer images using Gemini's API.
        """
        logger.info(f"Grading with Gemini: {len(question_image_paths)} question images vs {len(answer_image_paths)} answer images.")
        logger.info(f"Question image paths: {question_image_paths}")
        logger.info(f"Answer image paths: {answer_image_paths}")

        try:
            # Build the initial message
            initial_text = "H√£y ch·∫•m b√†i t·ª± lu·∫≠n to√°n c·ªßa h·ªçc sinh."

            # Add clarification context if re-grading
            if clarify and previous_grading:
                initial_text += f"\n\n**CH·∫§M L·∫†I V·ªöI CLARIFICATION:**\n"
                initial_text += f"Th·∫ßy c√¥ clarify: {clarify}\n"
                initial_text += f"L·∫ßn ch·∫•m tr∆∞·ªõc k·∫øt qu·∫£ l√†: ƒê√∫ng={previous_grading.get('is_correct', 'N/A')}, "
                initial_text += f"L·ªói='{previous_grading.get('error_description', 'N/A')}'\n"
                initial_text += f"D·ª±a v√†o clarification n√†y, h√£y ch·∫•m l·∫°i c√¢u h·ªèi v·ªõi s·ª± ch√∫ √Ω ƒë·∫∑c bi·ªát ƒë·∫øn ph·∫ßn th·∫ßy c√¥ ƒë√£ ch·ªâ ra."

            # Prepare parts list - text should be Part.from_text()
            parts = [types.Part.from_text(text=initial_text)]

            # Add question images
            for img_path in question_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Question image not found: {img_path}")

                # Read image as bytes for Gemini
                with open(img_path, "rb") as f:
                    image_data = f.read()

                parts.append(types.Part.from_bytes(
                    data=image_data,
                    mime_type=self._get_image_mime_type(img_path)
                ))

            # Add answer images
            for img_path in answer_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Answer image not found: {img_path}")

                # Read image as bytes for Gemini
                with open(img_path, "rb") as f:
                    image_data = f.read()

                parts.append(types.Part.from_bytes(
                    data=image_data,
                    mime_type=self._get_image_mime_type(img_path)
                ))

            # Make API call to Gemini
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[
                    types.Content(
                        role="user",
                        parts=parts
                    )
                ],
                config=types.GenerateContentConfig(
                    system_instruction=self.VISION_GRADING_PROMPT,
                    max_output_tokens=5000,
                    response_mime_type="application/json"
                )
            )

            # Log the response for debugging
            logger.info(f"Gemini API response received for grading")

            # Parse JSON response
            result_json = json.loads(response.text)
            return result_json

        except json.JSONDecodeError as e:
            logger.error(f"Gemini response JSON parsing failed: {e}")
            raise
        except Exception as e:
            logger.error(f"Gemini grading failed: {e}")
            raise

    async def _grade_image_pair_async(self, question_image_paths: List[str], answer_image_paths: List[str],
                                     clarify: str = None, previous_grading: Dict[str, Any] = None) -> Dict[str, Any]:
        """Async version of grade_image_pair for batch processing"""
        logger.info(f"Async grading with Gemini: {len(question_image_paths)} question images vs {len(answer_image_paths)} answer images.")

        try:
            # Build the initial message
            initial_text = "H√£y ch·∫•m b√†i t·ª± lu·∫≠n to√°n c·ªßa h·ªçc sinh."

            # Add clarification context if re-grading
            if clarify and previous_grading:
                initial_text += f"\n\n**CH·∫§M L·∫†I V·ªöI CLARIFICATION:**\n"
                initial_text += f"Th·∫ßy c√¥ clarify: {clarify}\n"
                initial_text += f"L·∫ßn ch·∫•m tr∆∞·ªõc k·∫øt qu·∫£ l√†: ƒê√∫ng={previous_grading.get('is_correct', 'N/A')}, "
                initial_text += f"L·ªói='{previous_grading.get('error_description', 'N/A')}'\n"
                initial_text += f"D·ª±a v√†o clarification n√†y, h√£y ch·∫•m l·∫°i c√¢u h·ªèi v·ªõi s·ª± ch√∫ √Ω ƒë·∫∑c bi·ªát ƒë·∫øn ph·∫ßn th·∫ßy c√¥ ƒë√£ ch·ªâ ra."

            # Prepare parts list - text should be Part.from_text()
            parts = [types.Part.from_text(text=initial_text)]

            # Add question images
            for img_path in question_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Question image not found: {img_path}")

                # Read image as bytes for Gemini
                with open(img_path, "rb") as f:
                    image_data = f.read()

                parts.append(types.Part.from_bytes(
                    data=image_data,
                    mime_type=self._get_image_mime_type(img_path)
                ))

            # Add answer images
            for img_path in answer_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Answer image not found: {img_path}")

                # Read image as bytes for Gemini
                with open(img_path, "rb") as f:
                    image_data = f.read()

                parts.append(types.Part.from_bytes(
                    data=image_data,
                    mime_type=self._get_image_mime_type(img_path)
                ))

            # Note: Gemini client might not have async support yet, so we'll use sync in async wrapper
            # This can be updated when Gemini adds proper async support
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[
                    types.Content(
                        role="user",
                        parts=parts
                    )
                ],
                config=types.GenerateContentConfig(
                    system_instruction=self.VISION_GRADING_PROMPT,
                    max_output_tokens=5000,
                    response_mime_type="application/json"
                )
            )

            result_json = json.loads(response.text)
            return result_json

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response: {e}")
            return {"is_correct": False, "confidence": 0.0, "error_description": "Failed to parse AI response", "error_phrases": [], "partial_credit": False}
        except Exception as e:
            logger.error(f"Async API request failed: {e}")
            return {"is_correct": False, "confidence": 0.0, "error_description": f"API error: {str(e)}", "error_phrases": [], "partial_credit": False}

    def grade_batch(self, items: List[Dict]) -> List[Dict[str, Any]]:
        """Override base method to use async processing with concurrency limit"""
        if not items:
            return []

        logger.info(f"Starting async batch grading for {len(items)} items with max 10 concurrent requests")
        return asyncio.run(self._grade_batch_async(items))

    async def _grade_batch_async(self, items: List[Dict]) -> List[Dict[str, Any]]:
        """Async batch processing with concurrency limit"""
        semaphore = asyncio.Semaphore(10)  # Max 10 concurrent requests

        async def process_item(item):
            async with semaphore:
                return await self._grade_image_pair_async(
                    question_image_paths=item['question_image_paths'],
                    answer_image_paths=item['answer_image_paths'],
                    clarify=item.get('clarify'),
                    previous_grading=item.get('previous_grading')
                )

        tasks = [process_item(item) for item in items]
        results = await asyncio.gather(*tasks)

        logger.info(f"Async batch grading completed for {len(items)} items")
        return results