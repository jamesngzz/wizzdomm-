import os
import base64
import json
import logging
import asyncio
from pathlib import Path
from typing import List, Dict, Any

from openai import AsyncOpenAI, OpenAI

from .base_model import BaseGradingModel
from core.llm_logger import log_llm_call, SERVICE_VISION_GRADING

# Setup logging
logger = logging.getLogger(__name__)

class OpenAIModel(BaseGradingModel):
    """
    An implementation of the BaseGradingModel using OpenAI's GPT Vision models.
    """
    
    # The detailed prompt is now part of this model-specific implementation.
    VISION_GRADING_PROMPT = """
M·ªôt gi√°o vi√™n To√°n Vi·ªát Nam t√†i gi·ªèi v·ªõi 20 nƒÉm kinh nghi·ªám, s·ªü tr∆∞·ªùng c·ªßa b·∫°n l√† ph√¢n t√≠ch s√¢u s·∫Øc logic gi·∫£i b√†i c·ªßa h·ªçc sinh v√† ƒë∆∞a ra nh·ªØng nh·∫≠n x√©t ch√≠nh x√°c, c√¥ng t√¢m.
**IMAGES INPUT:**
1.  **·∫¢NH ƒê·ªÄ B√ÄI:** N·ªôi dung c√¢u h·ªèi.
2.  **·∫¢NH B√ÄI L√ÄM:** L·ªùi gi·∫£i vi·∫øt tay c·ªßa h·ªçc sinh.

### **TRI·∫æT L√ù V√Ä QUY TR√åNH CH·∫§M B√ÄI**

**B∆∞·ªõc 1: ƒê·ªçc Hi·ªÉu To√†n Di·ªán v√† Nh·∫≠n Di·ªán S∆° B·ªô**
*   ƒê·∫ßu ti√™n, ƒë·ªçc k·ªπ **·∫¢NH ƒê·ªÄ B√ÄI** ƒë·ªÉ n·∫Øm v·ªØng y√™u c·∫ßu, ƒëi·ªÅu ki·ªán v√† m·ª•c ti√™u b√†i to√°n.
*   Ti·∫øp theo, ƒë·ªçc l∆∞·ªõt to√†n b·ªô **·∫¢NH B√ÄI L√ÄM**. M·ª•c ƒë√≠ch l√† hi·ªÉu t·ªïng quan v·ªÅ lu·ªìng t∆∞ duy, v√† c·∫•u tr√∫c b√†i gi·∫£i TR∆Ø·ªöC KHI ƒëi v√†o chi ti·∫øt.
*    **ƒê·∫∑c bi·ªát l∆∞u √Ω ƒë·∫øn nh·ªØng ƒëo·∫°n ch·ªØ vi·∫øt tay kh√¥ng r√µ r√†ng ho·∫∑c m∆° h·ªì**. T·∫°m th·ªùi ghi nh·∫≠n nh·ªØng ƒëi·ªÉm n√†y v√† chu·∫©n b·ªã tinh th·∫ßn ƒë·ªÉ √°p d·ª•ng k·ªπ thu·∫≠t gi·∫£i m√£ ng·ªØ c·∫£nh ·ªü b∆∞·ªõc sau, **tuy·ªát ƒë·ªëi kh√¥ng v·ªôi v√†ng ph√°n x√©t hay g√°n l·ªói ngay t·ª´ nh·ªØng k√Ω t·ª± kh√¥ng r√µ r√†ng ƒë·∫ßu ti√™n.**

**B∆∞·ªõc 2: Ph√¢n t√≠ch Logic S√¢u S·∫Øc v√† Gi·∫£i M√£ Ng·ªØ C·∫£nh (Root Cause Analysis)**
ƒê√¢y l√† b∆∞·ªõc quan tr·ªçng nh·∫•t. D√≤ theo t·ª´ng b∆∞·ªõc l·∫≠p lu·∫≠n c·ªßa h·ªçc sinh, k·∫øt h·ª£p ph√¢n t√≠ch logic v·ªõi k·ªπ nƒÉng gi·∫£i m√£ ch·ªØ vi·∫øt:

*   **2.1. H∆∞·ªõng ƒëi v√† Ph∆∞∆°ng ph√°p:**
    *   H·ªçc sinh c√≥ ch·ªçn ƒë√∫ng ph∆∞∆°ng ph√°p, ƒë·ªãnh l√Ω, c√¥ng th·ª©c ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ kh√¥ng?
    *   T∆∞ duy t·ªïng th·ªÉ c√≥ ƒëi ƒë√∫ng h∆∞·ªõng ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u c·ªßa b√†i to√°n kh√¥ng?
    *   T√¥i s·∫Ω ghi nh·∫≠n nh·ªØng √Ω t∆∞·ªüng ƒë√∫ng ƒë·∫Øn, d√π sau ƒë√≥ c√≥ th·ªÉ g·∫∑p l·ªói trong qu√° tr√¨nh th·ª±c thi.

*   **2.2. Gi·∫£i M√£ Ch·ªØ Vi·∫øt Kh√¥ng R√µ R√†ng (Contextual Character Interpretation):**
    *   ƒê√¢y l√† m·ªôt k·ªπ nƒÉng then ch·ªët. Khi g·∫∑p c√°c k√Ω t·ª±, s·ªë li·ªáu, ho·∫∑c bi·ªÉu th·ª©c vi·∫øt tay kh√¥ng r√µ r√†ng (v√≠ d·ª•: s·ªë 6 tr√¥ng nh∆∞ 8, '11' vi·∫øt g·∫ßn nhau d·ªÖ nh·∫ßm th√†nh 'n', d·∫•u ph√©p to√°n m∆° h·ªì, ch·ªØ 'x' v√† 'y' l·∫´n l·ªôn), **t√¥i s·∫Ω TUY·ªÜT ƒê·ªêI kh√¥ng v·ªôi v√†ng ƒë∆∞a ra ph√°n x√©t sai.**
    *   Thay v√†o ƒë√≥, **t·∫°m d·ª´ng v√† th·ª±c hi·ªán ph√¢n t√≠ch ng·ªØ c·∫£nh s√¢u r·ªông:**
        *   **Logic Bi·∫øn ƒê·ªïi Tr∆∞·ªõc v√† Sau:** T√¥i s·∫Ω d·ª±a v√†o c√°c b∆∞·ªõc l·∫≠p lu·∫≠n, ph√©p t√≠nh, v√† bi·∫øn ƒë·ªïi to√°n h·ªçc *ngay tr∆∞·ªõc v√† ngay sau* v·ªã tr√≠ k√Ω t·ª± ƒë√≥. Li·ªáu c√°ch ƒë·ªçc n√†o l√† h·ª£p l√Ω nh·∫•t ƒë·ªÉ duy tr√¨ t√≠nh li√™n t·ª•c v√† ƒë√∫ng ƒë·∫Øn c·ªßa lu·ªìng t∆∞ duy to√°n h·ªçc? V√≠ d·ª•, n·∫øu b∆∞·ªõc tr∆∞·ªõc l√† `2x + 4 = 10` v√† b∆∞·ªõc sau l√† `2x = 6`, th√¨ k√Ω t·ª± gi·ªØa c√≥ th·ªÉ l√† d·∫•u tr·ª´ (-) ho·∫∑c d·∫•u b·∫±ng (=), nh∆∞ng d·ª±a v√†o logic bi·∫øn ƒë·ªïi, n√≥ ph·∫£i l√† d·∫•u tr·ª´ (10 - 4 thay v√¨ 10 = 4).
        *   **∆Øu ti√™n √ù ƒê·ªãnh ƒê√∫ng (Principle of Charity):** N·∫øu c√≥ nhi·ªÅu c√°ch ƒë·ªçc kh·∫£ thi (v√≠ d·ª•: 6 hay 8), t√¥i s·∫Ω ∆∞u ti√™n c√°ch ƒë·ªçc n√†o gi√∫p cho l·∫≠p lu·∫≠n c·ªßa h·ªçc sinh c√≥ *kh·∫£ nƒÉng ƒë√∫ng* ho·∫∑c *√≠t sai s√≥t h∆°n* trong b·ªëi c·∫£nh chung c·ªßa b√†i gi·∫£i. M·ª•c ti√™u c·ªßa t√¥i l√† hi·ªÉu √Ω h·ªçc sinh v√† ƒë√°nh gi√° t∆∞ duy, kh√¥ng ph·∫£i t√¨m l·ªói d·ª±a tr√™n s·ª± m∆° h·ªì c·ªßa ch·ªØ vi·∫øt.
        *   **M·ªü R·ªông Ph·∫°m Vi Ph√¢n T√≠ch:** ƒê√¥i khi c·∫ßn xem x√©t c·∫£ m·ªôt ƒëo·∫°n vƒÉn b·∫£n, m·ªôt ph√©p t√≠nh l·ªõn h∆°n ho·∫∑c th·∫≠m ch√≠ to√†n b·ªô ph∆∞∆°ng tr√¨nh ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c √Ω ƒë·ªì c·ªßa h·ªçc sinh, thay v√¨ ch·ªâ t·∫≠p trung v√†o m·ªôt k√Ω t·ª± ƒë∆°n l·∫ª.

*   **2.3. T√¨m "L·ªói G·ªëc" (Root Cause Analysis):**
    *   N·∫øu c√≥ nhi·ªÅu l·ªói sai, t√¥i s·∫Ω t·∫≠p trung v√†o **l·ªói sai ƒë·∫ßu ti√™n v√† c∆° b·∫£n nh·∫•t** ƒë√£ g√¢y ra chu·ªói sai l·∫ßm sau ƒë√≥. V√≠ d·ª•, n·∫øu h·ªçc sinh t√≠nh sai bi·ªát th·ª©c Delta ngay t·ª´ ƒë·∫ßu, d·∫´n ƒë·∫øn to√†n b·ªô ph·∫ßn t√¨m nghi·ªám ph√≠a sau ƒë·ªÅu sai, th√¨ "l·ªói g·ªëc" l√† "T√≠nh sai bi·ªát th·ª©c Delta". T√¥i s·∫Ω ch·ªâ ra l·ªói g·ªëc n√†y ƒë·ªÉ h·ªçc sinh hi·ªÉu v·∫•n ƒë·ªÅ c·ªët l√µi c·∫ßn kh·∫Øc ph·ª•c.

### **TI√äU CH√ç ƒê√ÅNH GI√Å**
‚úÖ ƒê√öNG: Khi **ph∆∞∆°ng ph√°p + ƒë√°p √°n** ƒë·ªÅu ƒë√∫ng. L·ªùi gi·∫£i h·ª£p l√Ω v·ªÅ m·∫∑t to√°n h·ªçc, kh√¥ng ch·ª©a l·ªói logic nghi√™m tr·ªçng.
üîÑ ƒêI·ªÇM M·ªòT PH·∫¶N: Ph∆∞∆°ng ph√°p ƒë√∫ng ho·∫∑c ƒë√°p √°n ƒë√∫ng nh∆∞ng sai s√≥t nh·ªè trong t√≠nh to√°n, ho·∫∑c c√°c l·ªói kh√¥ng ƒë√°ng k·ªÉ.
‚ùå SAI: Ph∆∞∆°ng ph√°p sai ho·∫∑c ƒë√°p √°n sai ho·∫∑c ƒë√∫ng m·ªôt c√°ch "may m·∫Øn" nh∆∞ng c√≥ l·ªó h·ªïng logic nghi·ªám tr·ªçng.
‚ùå KH√îNG L√ÄM B√ÄI: B·ªè tr·ªëng ho·∫∑c b√†i l√†m kh√¥ng ƒë·ªçc ƒë∆∞·ª£c.

### **Y√äU C·∫¶U OUTPUT (B·∫ÆT BU·ªòC)**

B·∫°n ph·∫£i tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON duy nh·∫•t v·ªõi c·∫•u tr√∫c ch√≠nh x√°c nh∆∞ sau:

```json
{
  "is_correct": true/false,
  "critical_errors": [
    {
      "description": "M√¥ t·∫£ l·ªói nghi√™m tr·ªçng ·∫£nh h∆∞·ªüng ƒë·∫øn logic ch√≠nh",
      "phrases": ["Phrase ng·∫Øn g·ªçn m√¥ t·∫£ l·ªói", "Phrase kh√°c n·∫øu c√≥"]
    }
  ], #L·ªói sai ch√≠ m·∫°ng l√†m ·∫£nh h∆∞·ªüng nhi·ªÅu ƒë·∫øn m·∫°ch logic l√†m b√†i. VD: Sai ph∆∞∆°ng ph√°p, sai c√¥ng th·ª©c ch√≠nh
  "part_errors": [
    {
      "description": "M√¥ t·∫£ l·ªói nh·ªè ho·∫∑c kh√¥ng ch·∫Øc ch·∫Øn do OCR",
      "phrases": ["Phrase ng·∫Øn g·ªçn", "Phrase kh√°c n·∫øu c√≥"]
    }
  ], #L·ªói nh·ªè, kh√¥ng ƒë√°ng k·ªÉ ho·∫∑c kh√¥ng ch·∫Øc ch·∫Øn do ch·ªØ vi·∫øt kh√¥ng r√µ r√†ng. VD: Sai t√≠nh to√°n nh·ªè, vi·∫øt m∆° h·ªì
  "partial_credit": true/false #Trong qu√° tr√¨nh l√†m b√†i t·ªìn t·∫°i nh·ªØng b∆∞·ªõc ƒë√∫ng
}

**CH·ªà D·∫™N PH√ÇN LO·∫†I L·ªñI:**
- **CRITICAL_ERRORS (M√†u ƒë·ªè):** L·ªói l√†m sai l·ªách ho√†n to√†n logic b√†i l√†m, ·∫£nh h∆∞·ªüng ƒë·∫øn k·∫øt qu·∫£ cu·ªëi
- **PART_ERRORS (M√†u v√†ng):** L·ªói nh·ªè, kh√¥ng ·∫£nh h∆∞·ªüng logic ch√≠nh, ho·∫∑c do kh√¥ng ch·∫Øc ch·∫Øn khi ƒë·ªçc ch·ªØ vi·∫øt
- N·∫øu kh√¥ng c√≥ l·ªói n√†o trong lo·∫°i ƒë√≥ th√¨ ƒë·ªÉ array r·ªóng []
- M·ªói error c√≥ description (chi ti·∫øt) v√† phrases (ng·∫Øn g·ªçn ƒë·ªÉ hi·ªÉn th·ªã)
"""

    def __init__(self, api_key: str, model_name: str = "gpt-4o"):
        if not api_key:
            raise ValueError("OpenAI API key is required.")
        self.client = OpenAI(api_key=api_key)
        self.async_client = AsyncOpenAI(api_key=api_key)
        self.model_name = model_name
        logger.info(f"OpenAIModel initialized with model: {self.model_name}")

    def _encode_image(self, image_path: str) -> str:
        """Encode image to base64."""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"Failed to encode image {image_path}: {e}")
            raise

    def _get_image_mime_type(self, image_path: str) -> str:
        """Determine MIME type from file extension."""
        ext = Path(image_path).suffix.lower()
        return {'.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png'}.get(ext, 'image/jpeg')

    def grade_image_pair(self, question_image_paths: List[str], answer_image_paths: List[str],
                        clarify: str = None, previous_grading: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Grades a student's answer by analyzing question and answer images using OpenAI's API.
        """
        logger.info(f"Grading with OpenAI: {len(question_image_paths)} question images vs {len(answer_image_paths)} answer images.")
        logger.info(f"Question image paths: {question_image_paths}")
        logger.info(f"Answer image paths: {answer_image_paths}")

        try:
            # Build the initial message
            initial_text = "H√£y ch·∫•m b√†i t·ª± lu·∫≠n to√°n c·ªßa h·ªçc sinh."

            # Add clarification context if re-grading
            if clarify and previous_grading:
                initial_text += f"\n\n**CH·∫§M L·∫†I V·ªöI CLARIFICATION:**\n"
                initial_text += f"Th·∫ßy c√¥ clarify: {clarify}\n"
                initial_text += f"L·∫ßn ch·∫•m tr∆∞·ªõc k·∫øt qu·∫£ l√†: ƒê√∫ng={previous_grading.get('is_correct', 'N/A')}, "
                initial_text += f"L·ªói='{previous_grading.get('error_description', 'N/A')}'\n"
                initial_text += f"D·ª±a v√†o clarification n√†y, h√£y ch·∫•m l·∫°i c√¢u h·ªèi v·ªõi s·ª± ch√∫ √Ω ƒë·∫∑c bi·ªát ƒë·∫øn ph·∫ßn th·∫ßy c√¥ ƒë√£ ch·ªâ ra."

            message_content = [{"type": "text", "text": initial_text}]

            # Add question images
            for img_path in question_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Question image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            # Add answer images
            for img_path in answer_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Answer image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            messages = [
                {"role": "system", "content": self.VISION_GRADING_PROMPT},
                {"role": "user", "content": message_content}
            ]

            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_completion_tokens=5000,
                response_format={"type": "json_object"}
            )

            log_llm_call(response, self.model_name, SERVICE_VISION_GRADING)
            
            result_json = json.loads(response.choices[0].message.content)
            return result_json

        except json.JSONDecodeError as e:
            logger.error(f"OpenAI response JSON parsing failed: {e}")
            raise
        except Exception as e:
            logger.error(f"OpenAI grading failed: {e}")
            raise

    async def _grade_image_pair_async(self, question_image_paths: List[str], answer_image_paths: List[str],
                                     clarify: str = None, previous_grading: Dict[str, Any] = None) -> Dict[str, Any]:
        """Async version of grade_image_pair for batch processing"""
        logger.info(f"Async grading with OpenAI: {len(question_image_paths)} question images vs {len(answer_image_paths)} answer images.")
        
        try:
            # Build the initial message
            initial_text = "H√£y ch·∫•m b√†i t·ª± lu·∫≠n to√°n c·ªßa h·ªçc sinh."

            # Add clarification context if re-grading
            if clarify and previous_grading:
                initial_text += f"\n\n**CH·∫§M L·∫†I V·ªöI CLARIFICATION:**\n"
                initial_text += f"Th·∫ßy c√¥ clarify: {clarify}\n"
                initial_text += f"L·∫ßn ch·∫•m tr∆∞·ªõc k·∫øt qu·∫£ l√†: ƒê√∫ng={previous_grading.get('is_correct', 'N/A')}, "
                initial_text += f"L·ªói='{previous_grading.get('error_description', 'N/A')}'\n"
                initial_text += f"D·ª±a v√†o clarification n√†y, h√£y ch·∫•m l·∫°i c√¢u h·ªèi v·ªõi s·ª± ch√∫ √Ω ƒë·∫∑c bi·ªát ƒë·∫øn ph·∫ßn th·∫ßy c√¥ ƒë√£ ch·ªâ ra."

            message_content = [{"type": "text", "text": initial_text}]

            # Add question images
            for img_path in question_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Question image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            # Add answer images
            for img_path in answer_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Answer image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            messages = [
                {"role": "system", "content": self.VISION_GRADING_PROMPT},
                {"role": "user", "content": message_content}
            ]

            response = await self.async_client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_completion_tokens=5000,
                response_format={"type": "json_object"}
            )

            log_llm_call(response, self.model_name, SERVICE_VISION_GRADING)
            
            result_json = json.loads(response.choices[0].message.content)
            return result_json

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response: {e}")
            return {"is_correct": False, "critical_errors": [{"description": "Failed to parse AI response", "phrases": []}], "part_errors": [], "partial_credit": False}
        except Exception as e:
            logger.error(f"Async API request failed: {e}")
            return {"is_correct": False, "critical_errors": [{"description": f"API error: {str(e)}", "phrases": []}], "part_errors": [], "partial_credit": False}

    def grade_batch(self, items: List[Dict]) -> List[Dict[str, Any]]:
        """Override base method to use async processing with concurrency limit"""
        if not items:
            return []
            
        logger.info(f"Starting async batch grading for {len(items)} items with max 10 concurrent requests")
        return asyncio.run(self._grade_batch_async(items))
    
    async def _grade_batch_async(self, items: List[Dict]) -> List[Dict[str, Any]]:
        """Async batch processing with concurrency limit"""
        semaphore = asyncio.Semaphore(10)  # Max 10 concurrent requests
        
        async def process_item(item):
            async with semaphore:
                return await self._grade_image_pair_async(
                    question_image_paths=item['question_image_paths'],
                    answer_image_paths=item['answer_image_paths'],
                    clarify=item.get('clarify'),
                    previous_grading=item.get('previous_grading')
                )
        
        tasks = [process_item(item) for item in items]
        results = await asyncio.gather(*tasks)
        
        logger.info(f"Async batch grading completed for {len(items)} items")
        return results