import os
import base64
import json
import logging
import asyncio
from pathlib import Path
from typing import List, Dict, Any

from openai import AsyncOpenAI, OpenAI

from .base_model import BaseGradingModel
from core.llm_logger import log_llm_call, SERVICE_VISION_GRADING

# Setup logging
logger = logging.getLogger(__name__)

class OpenAIModel(BaseGradingModel):
    """
    An implementation of the BaseGradingModel using OpenAI's GPT Vision models.
    """
    
    # The detailed prompt is now part of this model-specific implementation.
    VISION_GRADING_PROMPT = """
Má»™t giÃ¡o viÃªn ToÃ¡n Viá»‡t Nam tÃ i giá»i vá»›i 20 nÄƒm kinh nghiá»‡m, sá»Ÿ trÆ°á»ng cá»§a báº¡n lÃ  phÃ¢n tÃ­ch sÃ¢u sáº¯c logic giáº£i bÃ i cá»§a há»c sinh vÃ  Ä‘Æ°a ra nhá»¯ng nháº­n xÃ©t chÃ­nh xÃ¡c, cÃ´ng tÃ¢m.
**IMAGES INPUT:**
1.  **áº¢NH Äá»€ BÃ€I:** Ná»™i dung cÃ¢u há»i.
2.  **áº¢NH BÃ€I LÃ€M:** Lá»i giáº£i viáº¿t tay cá»§a há»c sinh.

### **TRIáº¾T LÃ VÃ€ QUY TRÃŒNH CHáº¤M BÃ€I**

**BÆ°á»›c 1: Äá»c Hiá»ƒu ToÃ n Diá»‡n vÃ  Nháº­n Diá»‡n SÆ¡ Bá»™**
*   Äáº§u tiÃªn, Ä‘á»c ká»¹ **áº¢NH Äá»€ BÃ€I** Ä‘á»ƒ náº¯m vá»¯ng yÃªu cáº§u, Ä‘iá»u kiá»‡n vÃ  má»¥c tiÃªu bÃ i toÃ¡n.
*   Tiáº¿p theo, Ä‘á»c lÆ°á»›t toÃ n bá»™ **áº¢NH BÃ€I LÃ€M**. Má»¥c Ä‘Ã­ch lÃ  hiá»ƒu tá»•ng quan vá» luá»“ng tÆ° duy, vÃ  cáº¥u trÃºc bÃ i giáº£i TRÆ¯á»šC KHI Ä‘i vÃ o chi tiáº¿t.
*    **Äáº·c biá»‡t lÆ°u Ã½ Ä‘áº¿n nhá»¯ng Ä‘oáº¡n chá»¯ viáº¿t tay khÃ´ng rÃµ rÃ ng hoáº·c mÆ¡ há»“**. Táº¡m thá»i ghi nháº­n nhá»¯ng Ä‘iá»ƒm nÃ y vÃ  chuáº©n bá»‹ tinh tháº§n Ä‘á»ƒ Ã¡p dá»¥ng ká»¹ thuáº­t giáº£i mÃ£ ngá»¯ cáº£nh á»Ÿ bÆ°á»›c sau, **tuyá»‡t Ä‘á»‘i khÃ´ng vá»™i vÃ ng phÃ¡n xÃ©t hay gÃ¡n lá»—i ngay tá»« nhá»¯ng kÃ½ tá»± khÃ´ng rÃµ rÃ ng Ä‘áº§u tiÃªn.**

**BÆ°á»›c 2: PhÃ¢n tÃ­ch Logic SÃ¢u Sáº¯c vÃ  Giáº£i MÃ£ Ngá»¯ Cáº£nh (Root Cause Analysis)**
ÄÃ¢y lÃ  bÆ°á»›c quan trá»ng nháº¥t. DÃ² theo tá»«ng bÆ°á»›c láº­p luáº­n cá»§a há»c sinh, káº¿t há»£p phÃ¢n tÃ­ch logic vá»›i ká»¹ nÄƒng giáº£i mÃ£ chá»¯ viáº¿t:

*   **2.1. HÆ°á»›ng Ä‘i vÃ  PhÆ°Æ¡ng phÃ¡p:**
    *   Há»c sinh cÃ³ chá»n Ä‘Ãºng phÆ°Æ¡ng phÃ¡p, Ä‘á»‹nh lÃ½, cÃ´ng thá»©c Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» khÃ´ng?
    *   TÆ° duy tá»•ng thá»ƒ cÃ³ Ä‘i Ä‘Ãºng hÆ°á»›ng Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu cá»§a bÃ i toÃ¡n khÃ´ng?
    *   TÃ´i sáº½ ghi nháº­n nhá»¯ng Ã½ tÆ°á»Ÿng Ä‘Ãºng Ä‘áº¯n, dÃ¹ sau Ä‘Ã³ cÃ³ thá»ƒ gáº·p lá»—i trong quÃ¡ trÃ¬nh thá»±c thi.

*   **2.2. Giáº£i MÃ£ Chá»¯ Viáº¿t KhÃ´ng RÃµ RÃ ng (Contextual Character Interpretation):**
    *   ÄÃ¢y lÃ  má»™t ká»¹ nÄƒng then chá»‘t. Khi gáº·p cÃ¡c kÃ½ tá»±, sá»‘ liá»‡u, hoáº·c biá»ƒu thá»©c viáº¿t tay khÃ´ng rÃµ rÃ ng (vÃ­ dá»¥: sá»‘ 6 trÃ´ng nhÆ° 8, '11' viáº¿t gáº§n nhau dá»… nháº§m thÃ nh 'n', dáº¥u phÃ©p toÃ¡n mÆ¡ há»“, chá»¯ 'x' vÃ  'y' láº«n lá»™n), **tÃ´i sáº½ TUYá»†T Äá»I khÃ´ng vá»™i vÃ ng Ä‘Æ°a ra phÃ¡n xÃ©t sai.**
    *   Thay vÃ o Ä‘Ã³, **táº¡m dá»«ng vÃ  thá»±c hiá»‡n phÃ¢n tÃ­ch ngá»¯ cáº£nh sÃ¢u rá»™ng:**
        *   **Logic Biáº¿n Äá»•i TrÆ°á»›c vÃ  Sau:** TÃ´i sáº½ dá»±a vÃ o cÃ¡c bÆ°á»›c láº­p luáº­n, phÃ©p tÃ­nh, vÃ  biáº¿n Ä‘á»•i toÃ¡n há»c *ngay trÆ°á»›c vÃ  ngay sau* vá»‹ trÃ­ kÃ½ tá»± Ä‘Ã³. Liá»‡u cÃ¡ch Ä‘á»c nÃ o lÃ  há»£p lÃ½ nháº¥t Ä‘á»ƒ duy trÃ¬ tÃ­nh liÃªn tá»¥c vÃ  Ä‘Ãºng Ä‘áº¯n cá»§a luá»“ng tÆ° duy toÃ¡n há»c? VÃ­ dá»¥, náº¿u bÆ°á»›c trÆ°á»›c lÃ  `2x + 4 = 10` vÃ  bÆ°á»›c sau lÃ  `2x = 6`, thÃ¬ kÃ½ tá»± giá»¯a cÃ³ thá»ƒ lÃ  dáº¥u trá»« (-) hoáº·c dáº¥u báº±ng (=), nhÆ°ng dá»±a vÃ o logic biáº¿n Ä‘á»•i, nÃ³ pháº£i lÃ  dáº¥u trá»« (10 - 4 thay vÃ¬ 10 = 4).
        *   **Æ¯u tiÃªn Ã Äá»‹nh ÄÃºng (Principle of Charity):** Náº¿u cÃ³ nhiá»u cÃ¡ch Ä‘á»c kháº£ thi (vÃ­ dá»¥: 6 hay 8), tÃ´i sáº½ Æ°u tiÃªn cÃ¡ch Ä‘á»c nÃ o giÃºp cho láº­p luáº­n cá»§a há»c sinh cÃ³ *kháº£ nÄƒng Ä‘Ãºng* hoáº·c *Ã­t sai sÃ³t hÆ¡n* trong bá»‘i cáº£nh chung cá»§a bÃ i giáº£i. Má»¥c tiÃªu cá»§a tÃ´i lÃ  hiá»ƒu Ã½ há»c sinh vÃ  Ä‘Ã¡nh giÃ¡ tÆ° duy, khÃ´ng pháº£i tÃ¬m lá»—i dá»±a trÃªn sá»± mÆ¡ há»“ cá»§a chá»¯ viáº¿t.
        *   **Má»Ÿ Rá»™ng Pháº¡m Vi PhÃ¢n TÃ­ch:** ÄÃ´i khi cáº§n xem xÃ©t cáº£ má»™t Ä‘oáº¡n vÄƒn báº£n, má»™t phÃ©p tÃ­nh lá»›n hÆ¡n hoáº·c tháº­m chÃ­ toÃ n bá»™ phÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c Ã½ Ä‘á»“ cá»§a há»c sinh, thay vÃ¬ chá»‰ táº­p trung vÃ o má»™t kÃ½ tá»± Ä‘Æ¡n láº».

*   **2.3. TÃ¬m "Lá»—i Gá»‘c" (Root Cause Analysis):**
    *   Náº¿u cÃ³ nhiá»u lá»—i sai, tÃ´i sáº½ táº­p trung vÃ o **lá»—i sai Ä‘áº§u tiÃªn vÃ  cÆ¡ báº£n nháº¥t** Ä‘Ã£ gÃ¢y ra chuá»—i sai láº§m sau Ä‘Ã³. VÃ­ dá»¥, náº¿u há»c sinh tÃ­nh sai biá»‡t thá»©c Delta ngay tá»« Ä‘áº§u, dáº«n Ä‘áº¿n toÃ n bá»™ pháº§n tÃ¬m nghiá»‡m phÃ­a sau Ä‘á»u sai, thÃ¬ "lá»—i gá»‘c" lÃ  "TÃ­nh sai biá»‡t thá»©c Delta". TÃ´i sáº½ chá»‰ ra lá»—i gá»‘c nÃ y Ä‘á»ƒ há»c sinh hiá»ƒu váº¥n Ä‘á» cá»‘t lÃµi cáº§n kháº¯c phá»¥c.

### **TIÃŠU CHÃ ÄÃNH GIÃ**
âœ… ÄÃšNG: Khi **phÆ°Æ¡ng phÃ¡p + Ä‘Ã¡p Ã¡n** Ä‘á»u Ä‘Ãºng. Lá»i giáº£i há»£p lÃ½ vá» máº·t toÃ¡n há»c, khÃ´ng chá»©a lá»—i logic nghiÃªm trá»ng.
ðŸ”„ ÄIá»‚M Má»˜T PHáº¦N: PhÆ°Æ¡ng phÃ¡p Ä‘Ãºng hoáº·c Ä‘Ã¡p Ã¡n Ä‘Ãºng nhÆ°ng sai sÃ³t nhá» trong tÃ­nh toÃ¡n, hoáº·c cÃ¡c lá»—i khÃ´ng Ä‘Ã¡ng ká»ƒ.
âŒ SAI: PhÆ°Æ¡ng phÃ¡p sai hoáº·c Ä‘Ã¡p Ã¡n sai hoáº·c Ä‘Ãºng má»™t cÃ¡ch "may máº¯n" nhÆ°ng cÃ³ lá»— há»•ng logic nghiá»‡m trá»ng.
âŒ KHÃ”NG LÃ€M BÃ€I: Bá» trá»‘ng hoáº·c bÃ i lÃ m khÃ´ng Ä‘á»c Ä‘Æ°á»£c.

### **YÃŠU Cáº¦U OUTPUT (Báº®T BUá»˜C)**

Báº¡n pháº£i tráº£ vá» má»™t Ä‘á»‘i tÆ°á»£ng JSON duy nháº¥t vá»›i cáº¥u trÃºc chÃ­nh xÃ¡c nhÆ° sau:

```json
{
  "is_correct": true/false,
  "critical_errors": [
    {
      "description": "MÃ´ táº£ lá»—i nghiÃªm trá»ng áº£nh hÆ°á»Ÿng Ä‘áº¿n logic chÃ­nh",
      "phrases": ["Phrase ngáº¯n gá»n mÃ´ táº£ lá»—i", "Phrase khÃ¡c náº¿u cÃ³"]
    }
  ], #Lá»—i sai chÃ­ máº¡ng lÃ m áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n máº¡ch logic lÃ m bÃ i. VD: Sai phÆ°Æ¡ng phÃ¡p, sai cÃ´ng thá»©c chÃ­nh
  "part_errors": [
    {
      "description": "MÃ´ táº£ lá»—i nhá» hoáº·c khÃ´ng cháº¯c cháº¯n do OCR",
      "phrases": ["Phrase ngáº¯n gá»n", "Phrase khÃ¡c náº¿u cÃ³"]
    }
  ], #Lá»—i nhá», khÃ´ng Ä‘Ã¡ng ká»ƒ hoáº·c khÃ´ng cháº¯c cháº¯n do chá»¯ viáº¿t khÃ´ng rÃµ rÃ ng. VD: Sai tÃ­nh toÃ¡n nhá», viáº¿t mÆ¡ há»“
  "partial_credit": true/false #Trong quÃ¡ trÃ¬nh lÃ m bÃ i tá»“n táº¡i nhá»¯ng bÆ°á»›c Ä‘Ãºng
}

**CHá»ˆ DáºªN PHÃ‚N LOáº I Lá»–I:**
- **CRITICAL_ERRORS (MÃ u Ä‘á»):** Lá»—i lÃ m sai lá»‡ch hoÃ n toÃ n logic bÃ i lÃ m, áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ cuá»‘i
- **PART_ERRORS (MÃ u vÃ ng):** Lá»—i nhá», khÃ´ng áº£nh hÆ°á»Ÿng logic chÃ­nh, hoáº·c do khÃ´ng cháº¯c cháº¯n khi Ä‘á»c chá»¯ viáº¿t
- Náº¿u khÃ´ng cÃ³ lá»—i nÃ o trong loáº¡i Ä‘Ã³ thÃ¬ Ä‘á»ƒ array rá»—ng []
- Má»—i error cÃ³ description (chi tiáº¿t) vÃ  phrases (ngáº¯n gá»n Ä‘á»ƒ hiá»ƒn thá»‹)
"""

    def __init__(self, api_key: str, model_name: str = "gpt-4o"):
        if not api_key:
            raise ValueError("OpenAI API key is required.")
        self.client = OpenAI(api_key=api_key)
        self.async_client = AsyncOpenAI(api_key=api_key)
        self.model_name = model_name
        logger.info(f"OpenAIModel initialized with model: {self.model_name}")

    def _encode_image(self, image_path: str) -> str:
        """Encode image to base64."""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"Failed to encode image {image_path}: {e}")
            raise

    def _get_image_mime_type(self, image_path: str) -> str:
        """Determine MIME type from file extension."""
        ext = Path(image_path).suffix.lower()
        return {'.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png'}.get(ext, 'image/jpeg')

    def grade_image_pair(self, question_image_paths: List[str], answer_image_paths: List[str],
                        clarify: str = None, previous_grading: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Grades a student's answer by analyzing question and answer images using OpenAI's API.
        """
        logger.info(f"Grading with OpenAI: {len(question_image_paths)} question images vs {len(answer_image_paths)} answer images.")
        logger.info(f"Question image paths: {question_image_paths}")
        logger.info(f"Answer image paths: {answer_image_paths}")

        try:
            # Build the initial message
            initial_text = "HÃ£y cháº¥m bÃ i tá»± luáº­n toÃ¡n cá»§a há»c sinh."

            # Add clarification context if re-grading
            if clarify and previous_grading:
                initial_text += f"\n\n**CHáº¤M Láº I Vá»šI CLARIFICATION:**\n"
                initial_text += f"Tháº§y cÃ´ clarify: {clarify}\n"
                initial_text += f"Láº§n cháº¥m trÆ°á»›c káº¿t quáº£ lÃ : ÄÃºng={previous_grading.get('is_correct', 'N/A')}, "
                initial_text += f"Lá»—i='{previous_grading.get('error_description', 'N/A')}'\n"
                initial_text += f"Dá»±a vÃ o clarification nÃ y, hÃ£y cháº¥m láº¡i cÃ¢u há»i vá»›i sá»± chÃº Ã½ Ä‘áº·c biá»‡t Ä‘áº¿n pháº§n tháº§y cÃ´ Ä‘Ã£ chá»‰ ra."

            message_content = [{"type": "text", "text": initial_text}]

            # Add question images
            for img_path in question_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Question image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            # Add answer images
            for img_path in answer_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Answer image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            messages = [
                {"role": "system", "content": self.VISION_GRADING_PROMPT},
                {"role": "user", "content": message_content}
            ]

            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_completion_tokens=5000,
                response_format={"type": "json_object"}
            )

            log_llm_call(response, self.model_name, SERVICE_VISION_GRADING)
            
            result_json = json.loads(response.choices[0].message.content)
            return result_json

        except json.JSONDecodeError as e:
            logger.error(f"OpenAI response JSON parsing failed: {e}")
            raise
        except Exception as e:
            logger.error(f"OpenAI grading failed: {e}")
            raise

    async def _grade_image_pair_async(self, question_image_paths: List[str], answer_image_paths: List[str],
                                     clarify: str = None, previous_grading: Dict[str, Any] = None) -> Dict[str, Any]:
        """Async version of grade_image_pair for batch processing"""
        logger.info(f"Async grading with OpenAI: {len(question_image_paths)} question images vs {len(answer_image_paths)} answer images.")
        
        try:
            # Build the initial message
            initial_text = "HÃ£y cháº¥m bÃ i tá»± luáº­n toÃ¡n cá»§a há»c sinh."

            # Add clarification context if re-grading
            if clarify and previous_grading:
                initial_text += f"\n\n**CHáº¤M Láº I Vá»šI CLARIFICATION:**\n"
                initial_text += f"Tháº§y cÃ´ clarify: {clarify}\n"
                initial_text += f"Láº§n cháº¥m trÆ°á»›c káº¿t quáº£ lÃ : ÄÃºng={previous_grading.get('is_correct', 'N/A')}, "
                initial_text += f"Lá»—i='{previous_grading.get('error_description', 'N/A')}'\n"
                initial_text += f"Dá»±a vÃ o clarification nÃ y, hÃ£y cháº¥m láº¡i cÃ¢u há»i vá»›i sá»± chÃº Ã½ Ä‘áº·c biá»‡t Ä‘áº¿n pháº§n tháº§y cÃ´ Ä‘Ã£ chá»‰ ra."

            message_content = [{"type": "text", "text": initial_text}]

            # Add question images
            for img_path in question_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Question image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            # Add answer images
            for img_path in answer_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Answer image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            messages = [
                {"role": "system", "content": self.VISION_GRADING_PROMPT},
                {"role": "user", "content": message_content}
            ]

            response = await self.async_client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_completion_tokens=5000,
                response_format={"type": "json_object"}
            )

            log_llm_call(response, self.model_name, SERVICE_VISION_GRADING)
            
            result_json = json.loads(response.choices[0].message.content)
            return result_json

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response: {e}")
            return {"is_correct": False, "critical_errors": [{"description": "Failed to parse AI response", "phrases": []}], "part_errors": [], "partial_credit": False}
        except Exception as e:
            logger.error(f"Async API request failed: {e}")
            return {"is_correct": False, "critical_errors": [{"description": f"API error: {str(e)}", "phrases": []}], "part_errors": [], "partial_credit": False}

    def grade_batch(self, items: List[Dict]) -> List[Dict[str, Any]]:
        """Override base method to use async processing with concurrency limit"""
        if not items:
            return []
            
        logger.info(f"Starting async batch grading for {len(items)} items with max 10 concurrent requests")
        return asyncio.run(self._grade_batch_async(items))
    
    async def _grade_batch_async(self, items: List[Dict]) -> List[Dict[str, Any]]:
        """Async batch processing with concurrency limit"""
        semaphore = asyncio.Semaphore(10)  # Max 10 concurrent requests
        
        async def process_item(item):
            async with semaphore:
                return await self._grade_image_pair_async(
                    question_image_paths=item['question_image_paths'],
                    answer_image_paths=item['answer_image_paths'],
                    clarify=item.get('clarify'),
                    previous_grading=item.get('previous_grading')
                )
        
        tasks = [process_item(item) for item in items]
        results = await asyncio.gather(*tasks)
        
        logger.info(f"Async batch grading completed for {len(items)} items")
        return results