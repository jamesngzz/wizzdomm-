import os
import json
import base64
import logging
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path
from dataclasses import dataclass
from datetime import datetime

from dotenv import load_dotenv
from openai import OpenAI

from .llm_logger import log_llm_call, log_batch_summary, SERVICE_VISION_GRADING, SERVICE_BATCH_GRADING

# Load environment variables
load_dotenv()

# Setup logging
logger = logging.getLogger(__name__)

@dataclass
class GradingResult:
    """Data class for grading results"""
    question_id: int
    submission_item_id: int
    is_correct: bool
    confidence: float
    error_description: str
    error_phrases: List[str] = None
    partial_credit: bool = False
    processing_time: float = 0.0
    created_at: datetime = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.error_phrases is None:
            self.error_phrases = []

class VisionGradingService:
    
    # Enhanced grading prompt optimized through testing
    VISION_GRADING_PROMPT = """
Má»™t giÃ¡o viÃªn ToÃ¡n Viá»‡t Nam tÃ i giá»i vá»›i 20 nÄƒm kinh nghiá»‡m, sá»Ÿ trÆ°á»ng cá»§a báº¡n lÃ  phÃ¢n tÃ­ch sÃ¢u sáº¯c logic giáº£i bÃ i cá»§a há»c sinh vÃ  Ä‘Æ°a ra nhá»¯ng nháº­n xÃ©t chÃ­nh xÃ¡c, cÃ´ng tÃ¢m.
**IMAGES INPUT:**
1.  **áº¢NH Äá»€ BÃ€I:** Ná»™i dung cÃ¢u há»i.
2.  **áº¢NH BÃ€I LÃ€M:** Lá»i giáº£i viáº¿t tay cá»§a há»c sinh.

### **TRIáº¾T LÃ VÃ€ QUY TRÃŒNH CHáº¤M BÃ€I**
**BÆ°á»›c 1: Äá»c Hiá»ƒu ToÃ n Diá»‡n**
Äáº§u tiÃªn, Ä‘á»c ká»¹ **áº¢NH Äá»€ BÃ€I**, náº¯m vá»¯ng yÃªu cáº§u. 
Sau Ä‘Ã³, Ä‘á»c lÆ°á»›t toÃ n bá»™ **áº¢NH BÃ€I LÃ€M** Ä‘á»ƒ hiá»ƒu luá»“ng tÆ° duy tá»•ng thá»ƒ cá»§a há»c sinh TRÆ¯á»šC KHI Ä‘i vÃ o chi tiáº¿t. 
Äá»«ng vá»™i vÃ ng phÃ¡n xÃ©t ngay tá»« lá»—i sai Ä‘áº§u tiÃªn.
**BÆ°á»›c 2: PhÃ¢n tÃ­ch Logic vÃ  TÃ¬m "Lá»—i Gá»‘c" (Root Cause Analysis)**
ÄÃ¢y lÃ  bÆ°á»›c quan trá»ng nháº¥t. HÃ£y dÃ² theo tá»«ng bÆ°á»›c láº­p luáº­n cá»§a há»c sinh:
*   **HÆ°á»›ng Ä‘i cÃ³ Ä‘Ãºng khÃ´ng?** Há»c sinh cÃ³ chá»n Ä‘Ãºng phÆ°Æ¡ng phÃ¡p, Ä‘á»‹nh lÃ½, cÃ´ng thá»©c Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» khÃ´ng?
*   **Thá»±c thi cÃ³ chÃ­nh xÃ¡c khÃ´ng?** Trong quÃ¡ trÃ¬nh biáº¿n Ä‘á»•i, tÃ­nh toÃ¡n, há»c sinh cÃ³ máº¯c lá»—i khÃ´ng? (vÃ­ dá»¥: chuyá»ƒn váº¿ sai dáº¥u, tÃ­nh toÃ¡n sai, Ã¡p dá»¥ng sai Ä‘iá»u kiá»‡n).
*   **TÃ¬m Lá»—i Gá»‘c:** Náº¿u cÃ³ nhiá»u lá»—i sai, hÃ£y táº­p trung vÃ o **lá»—i sai Ä‘áº§u tiÃªn vÃ  cÆ¡ báº£n nháº¥t** Ä‘Ã£ gÃ¢y ra chuá»—i sai láº§m sau Ä‘Ã³. VÃ­ dá»¥, náº¿u há»c sinh tÃ­nh sai Delta ngay tá»« Ä‘áº§u, dáº«n Ä‘áº¿n toÃ n bá»™ pháº§n tÃ¬m nghiá»‡m phÃ­a sau Ä‘á»u sai, thÃ¬ "lá»—i gá»‘c" lÃ  "TÃ­nh sai biá»‡t thá»©c Delta".
*   **CÃ´ng nháº­n ná»— lá»±c:** Náº¿u há»c sinh cÃ³ hÆ°á»›ng Ä‘i Ä‘Ãºng nhÆ°ng gáº·p lá»—i tÃ­nh toÃ¡n nhá», hÃ£y ghi nháº­n pháº§n tÆ° duy Ä‘Ãºng Ä‘áº¯n Ä‘Ã³.

### **TIÃŠU CHÃ ÄÃNH GIÃ**
âœ… ÄÃšNG: Khi **phÆ°Æ¡ng phÃ¡p + Ä‘Ã¡p Ã¡n** Ä‘á»u Ä‘Ãºng. Lá»i giáº£i há»£p lÃ½ vá» máº·t toÃ¡n há»c, khÃ´ng chá»©a lá»—i logic nghiÃªm trá»ng.
ðŸ”„ ÄIá»‚M Má»˜T PHáº¦N: PhÆ°Æ¡ng phÃ¡p Ä‘Ãºng hoáº·c Ä‘Ã¡p Ã¡n Ä‘Ãºng nhÆ°ng sai sÃ³t nhá» trong tÃ­nh toÃ¡n, hoáº·c cÃ¡c lá»—i khÃ´ng Ä‘Ã¡ng ká»ƒ.
âŒ SAI: PhÆ°Æ¡ng phÃ¡p sai hoáº·c Ä‘Ã¡p Ã¡n sai hoáº·c Ä‘Ãºng má»™t cÃ¡ch "may máº¯n" nhÆ°ng cÃ³ lá»— há»•ng logic nghiá»‡m trá»ng.
âŒ KHÃ”NG LÃ€M BÃ€I: Bá» trá»‘ng hoáº·c bÃ i lÃ m khÃ´ng Ä‘á»c Ä‘Æ°á»£c.

### **YÃŠU Cáº¦U OUTPUT (Báº®T BUá»˜C)**

Báº¡n pháº£i tráº£ vá» má»™t Ä‘á»‘i tÆ°á»£ng JSON duy nháº¥t vá»›i cáº¥u trÃºc chÃ­nh xÃ¡c nhÆ° sau:

```json
{
  "is_correct": true/false,
  "confidence": float, (tá»« 0 Ä‘áº¿n 1) #Má»©c Ä‘á»™ tá»± tin cá»§a Model khi cháº¥m bÃ i
  "error_description": "Giáº£i thÃ­ch chi tiáº¿t vá» cÃ¡c lá»—i", #Náº¿u Ä‘Ãºng vÃ  khÃ´ng cÃ³ lá»—i nÃ o cáº£ thÃ¬ tráº£ vá» NULL
  "error_phrases":"Lá»—i sai há»c sinh cá»¥ thá»ƒ" (tá»‘i Ä‘a 15 tá»« má»™t Ã½, tá»‘i Ä‘a 3 Ã½) VÃ­ dá»¥: ["MÃ¢u thuáº«n logic: kháº³ng Ä‘á»‹nh (x-3)^2020+(2y+6)^2022>0 rá»“i láº¡i suy ra =0", "Äáº·t Ä‘iá»u kiá»‡n cho phÆ°Æ¡ng trÃ¬nh chá»©a cÄƒn sai, pháº£i lÃ  ... chá»© khÃ´ng lÃ  ...",...]
  "partial_credit": true/false #Trong quÃ¡ trÃ¬nh lÃ m bÃ i tá»“n táº¡i nhá»¯ng bÆ°á»›c Ä‘Ãºng (VÃ­ dá»¥ logic giáº£i bÃ i gá»“m 4 bÆ°á»›c vÃ  Ä‘Ãºng hai bÆ°á»›c Ä‘áº§u)
}
```
### **VÃ Dá»¤ MINH Há»ŒA**

{
  "is_correct": false,
  "confidence": 0.96,
  "error_description": "Há»c sinh Ä‘Ã£ Ã¡p dá»¥ng Ä‘Ãºng cÃ¡c bÆ°á»›c giáº£i phÆ°Æ¡ng trÃ¬nh báº­c nháº¥t, bao gá»“m khai triá»ƒn, thu gá»n vÃ  chuyá»ƒn váº¿. Tuy nhiÃªn, cÃ³ má»™t lá»—i nhá» trong bÆ°á»›c tÃ­nh toÃ¡n cuá»‘i cÃ¹ng khi chuyá»ƒn háº¡ng tá»­ tá»± do tá»« váº¿ trÃ¡i sang váº¿ pháº£i: thay vÃ¬ (-1) + 1 = 0, há»c sinh Ä‘Ã£ viáº¿t (-1) - 1 = -2, dáº«n Ä‘áº¿n Ä‘Ã¡p Ã¡n sai. Lá»—i nÃ y lÃ  má»™t sai sÃ³t vá» ká»¹ nÄƒng tÃ­nh toÃ¡n/chuyá»ƒn dáº¥u, khÃ´ng pháº£i lá»—i vá» phÆ°Æ¡ng phÃ¡p tÆ° duy tá»•ng thá»ƒ.",
  "error_phrases":["Lá»—i tÃ­nh toÃ¡n khi chuyá»ƒn háº¡ng tá»­ tá»± do"]
  "partial_credit": true
}

"""

    def __init__(self, api_key: Optional[str] = None):
        """Initialize the grading service"""
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OpenAI API key is required. Set OPENAI_API_KEY environment variable.")
        
        self.client = OpenAI(api_key=self.api_key)
        self.model_name = "gpt-5-mini"
        
        logger.info(f"VisionGradingService initialized with model: {self.model_name}")
    
    def _encode_image(self, image_path: str) -> str:
        """Encode image to base64"""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"Failed to encode image {image_path}: {e}")
            raise
    
    def _get_image_mime_type(self, image_path: str) -> str:
        """Determine MIME type from file extension"""
        ext = Path(image_path).suffix.lower()
        mime_map = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.webp': 'image/webp'
        }
        return mime_map.get(ext, 'image/jpeg')
    
    def grade_image_pair(self, question_image_path: str, answer_image_path: str, 
                        question_image_paths: List[str] = None, answer_image_paths: List[str] = None) -> Dict[str, Any]:
        """
        Grade a student's answer by analyzing question and answer images
        
        Args:
            question_image_path: Path to the question image
            answer_image_path: Path to the student's answer image
            question_image_paths: List of paths for multi-image questions
            answer_image_paths: List of paths for multi-image answers
            
        Returns:
            Dictionary containing grading results
        """
        start_time = datetime.now()
        
        logger.info(f"Grading image pair: {Path(question_image_path).name} vs {Path(answer_image_path).name}")
        
        try:
            # Validate files exist
            if not os.path.exists(question_image_path):
                raise FileNotFoundError(f"Question image not found: {question_image_path}")
            if not os.path.exists(answer_image_path):
                raise FileNotFoundError(f"Answer image not found: {answer_image_path}")
            
            # Validate additional answer images if provided
            if answer_image_paths:
                for img_path in answer_image_paths:
                    if not os.path.exists(img_path):
                        logger.warning(f"Answer image not found: {img_path}")
            
            # Prepare message content
            message_content = [
                {
                    "type": "text",
                    "text": "HÃ£y cháº¥m bÃ i tá»± luáº­n toÃ¡n cá»§a há»c sinh. Báº¡n sáº½ nháº­n Ä‘áº§u vÃ o hÃ¬nh áº£nh bao gá»“m NHá»®NG HÃŒNH áº¢NH Äá»€ BÃ€I & HÃŒNH áº¢NH BÃ€I LÃ€M Há»ŒC SINH"
                }
            ]
            
            # Add question image(s)
            if question_image_paths and len(question_image_paths) > 1:
                # Multiple question images
                for i, img_path in enumerate(question_image_paths, 1):
                    if os.path.exists(img_path):
                        question_b64 = self._encode_image(img_path)
                        question_mime = self._get_image_mime_type(img_path)
                        message_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{question_mime};base64,{question_b64}",
                                "detail": "high"
                            }
                        })
            else:
                # Single question image (backward compatibility)
                question_b64 = self._encode_image(question_image_path)
                question_mime = self._get_image_mime_type(question_image_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{question_mime};base64,{question_b64}",
                        "detail": "high"
                    }
                })
            
            # Add answer image(s)
            if answer_image_paths and len(answer_image_paths) > 1:
                # Multiple answer images
                for i, img_path in enumerate(answer_image_paths, 1):
                    if os.path.exists(img_path):
                        answer_b64 = self._encode_image(img_path)
                        answer_mime = self._get_image_mime_type(img_path)
                        message_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{answer_mime};base64,{answer_b64}",
                                "detail": "high"
                            }
                        })
            else:
                # Single answer image (backward compatibility)
                answer_b64 = self._encode_image(answer_image_path)
                answer_mime = self._get_image_mime_type(answer_image_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{answer_mime};base64,{answer_b64}",
                        "detail": "high"
                    }
                })
            
            # Prepare API messages
            messages = [
                {
                    "role": "system",
                    "content": self.VISION_GRADING_PROMPT
                },
                {
                    "role": "user",
                    "content": message_content
                }
            ]
            
            # Call OpenAI API
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_completion_tokens=4000,
                response_format={"type": "json_object"}
            )
            
            # Log LLM usage
            log_llm_call(response, self.model_name, SERVICE_VISION_GRADING)
            
            # Parse response
            result_json = json.loads(response.choices[0].message.content)
            
            # Add metadata
            processing_time = (datetime.now() - start_time).total_seconds()
            result_json.update({
                "processing_time": processing_time
            })
            
            logger.info(f"Grading completed in {processing_time:.2f}s - Result: {result_json['is_correct']}")
            
            return result_json
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing failed: {e}")
            return self._error_result(f"AI response parsing failed: {e}")
            
        except Exception as e:
            logger.error(f"Grading failed: {e}")
            return self._error_result(f"Grading error: {e}")
    
    def _error_result(self, error_msg: str) -> Dict[str, Any]:
        """Return standardized error result"""
        return {
            "is_correct": False,
            "confidence": 0.0,
            "error_description": error_msg,
            "partial_credit": False,
            "processing_time": 0.0,
            "error": True
        }
    
    def grade_submission_items(self, submission_items: List[Dict]) -> List[GradingResult]:
        """
        Grade multiple submission items
        
        Args:
            submission_items: List of dicts with question_image_path, answer_image_path, etc.
            
        Returns:
            List of GradingResult objects
        """
        results = []
        batch_start_time = datetime.now()
        total_cost = 0.0
        
        logger.info(f"Grading batch of {len(submission_items)} items")
        
        for i, item in enumerate(submission_items, 1):
            logger.info(f"Processing item {i}/{len(submission_items)}")
            
            try:
                grading_result = self.grade_image_pair(
                    item['question_image_path'],
                    item['answer_image_path'],
                    question_image_paths=item.get('question_image_paths'),
                    answer_image_paths=item.get('answer_image_paths')
                )
                
                result = GradingResult(
                    question_id=item.get('question_id', 0),
                    submission_item_id=item.get('submission_item_id', 0),
                    is_correct=grading_result['is_correct'],
                    confidence=grading_result.get('confidence', 0.0),
                    error_description=grading_result['error_description'],
                    error_phrases=grading_result.get('error_phrases', []),
                    partial_credit=grading_result.get('partial_credit', False),
                    processing_time=grading_result.get('processing_time', 0.0)
                )
                
                results.append(result)
                
            except Exception as e:
                logger.error(f"Failed to grade item {i}: {e}")
                # Create error result
                error_result = GradingResult(
                    question_id=item.get('question_id', 0),
                    submission_item_id=item.get('submission_item_id', 0),
                    is_correct=False,
                    confidence=0.0,
                    error_description=f"Grading failed: {str(e)}",
                    error_phrases=[],
                    partial_credit=False
                )
                results.append(error_result)
        
        # Calculate batch processing time and log summary
        batch_time = (datetime.now() - batch_start_time).total_seconds()
        
        # Note: Actual cost calculation is done in individual calls via log_llm_call
        # This is just a summary log
        log_batch_summary(len(submission_items), 0.0, SERVICE_BATCH_GRADING)
        
        logger.info(f"Batch grading completed: {len(results)} results generated in {batch_time:.2f}s")
        return results


# Global service instance
_grading_service = None

def get_grading_service() -> VisionGradingService:
    """Get global grading service instance"""
    global _grading_service
    if _grading_service is None:
        _grading_service = VisionGradingService()
    return _grading_service

# Convenience functions
def grade_single_pair(question_image_path: str, answer_image_path: str) -> Dict[str, Any]:
    """Grade a single question-answer pair"""
    service = get_grading_service()
    return service.grade_image_pair(question_image_path, answer_image_path)

def grade_multiple_pairs(submission_items: List[Dict]) -> List[GradingResult]:
    """Grade multiple question-answer pairs"""
    service = get_grading_service()
    return service.grade_submission_items(submission_items)